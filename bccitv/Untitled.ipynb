{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffeeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the needed libraries\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4177f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element is not clickable at point (687, 1762)\n  (Session info: chrome=118.0.5993.89)\nStacktrace:\n\tGetHandleVerifier [0x00007FF737868EF2+54786]\n\t(No symbol) [0x00007FF7377D5612]\n\t(No symbol) [0x00007FF73768A64B]\n\t(No symbol) [0x00007FF7376D1A6B]\n\t(No symbol) [0x00007FF7376CFE39]\n\t(No symbol) [0x00007FF7376CDC08]\n\t(No symbol) [0x00007FF7376CCCC3]\n\t(No symbol) [0x00007FF7376C29CF]\n\t(No symbol) [0x00007FF7376EBE6A]\n\t(No symbol) [0x00007FF7376C22E6]\n\t(No symbol) [0x00007FF7376EC080]\n\t(No symbol) [0x00007FF737704D02]\n\t(No symbol) [0x00007FF7376EBC43]\n\t(No symbol) [0x00007FF7376C0941]\n\t(No symbol) [0x00007FF7376C1B84]\n\tGetHandleVerifier [0x00007FF737BB7F52+3524194]\n\tGetHandleVerifier [0x00007FF737C0D800+3874576]\n\tGetHandleVerifier [0x00007FF737C05D7F+3843215]\n\tGetHandleVerifier [0x00007FF737905086+694166]\n\t(No symbol) [0x00007FF7377E0A88]\n\t(No symbol) [0x00007FF7377DCA94]\n\t(No symbol) [0x00007FF7377DCBC2]\n\t(No symbol) [0x00007FF7377CCC83]\n\tBaseThreadInitThunk [0x00007FF8BF3B257D+29]\n\tRtlUserThreadStart [0x00007FF8BFF0AA78+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3576\\2096693866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Find and click on the \"International\" link on the homepage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0minternational_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPARTIAL_LINK_TEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"International\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0minternational_link\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Find and click on the \"Fixtures\" link on the International page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element is not clickable at point (687, 1762)\n  (Session info: chrome=118.0.5993.89)\nStacktrace:\n\tGetHandleVerifier [0x00007FF737868EF2+54786]\n\t(No symbol) [0x00007FF7377D5612]\n\t(No symbol) [0x00007FF73768A64B]\n\t(No symbol) [0x00007FF7376D1A6B]\n\t(No symbol) [0x00007FF7376CFE39]\n\t(No symbol) [0x00007FF7376CDC08]\n\t(No symbol) [0x00007FF7376CCCC3]\n\t(No symbol) [0x00007FF7376C29CF]\n\t(No symbol) [0x00007FF7376EBE6A]\n\t(No symbol) [0x00007FF7376C22E6]\n\t(No symbol) [0x00007FF7376EC080]\n\t(No symbol) [0x00007FF737704D02]\n\t(No symbol) [0x00007FF7376EBC43]\n\t(No symbol) [0x00007FF7376C0941]\n\t(No symbol) [0x00007FF7376C1B84]\n\tGetHandleVerifier [0x00007FF737BB7F52+3524194]\n\tGetHandleVerifier [0x00007FF737C0D800+3874576]\n\tGetHandleVerifier [0x00007FF737C05D7F+3843215]\n\tGetHandleVerifier [0x00007FF737905086+694166]\n\t(No symbol) [0x00007FF7377E0A88]\n\t(No symbol) [0x00007FF7377DCA94]\n\t(No symbol) [0x00007FF7377DCBC2]\n\t(No symbol) [0x00007FF7377CCC83]\n\tBaseThreadInitThunk [0x00007FF8BF3B257D+29]\n\tRtlUserThreadStart [0x00007FF8BFF0AA78+40]\n"
     ]
    }
   ],
   "source": [
    "# Set up the web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the BCCI homepage\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "try:\n",
    "    # Find and click on the \"International\" link on the homepage\n",
    "    international_link = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, \"International\")))\n",
    "    international_link.click()\n",
    "\n",
    "    # Find and click on the \"Fixtures\" link on the International page\n",
    "    fixtures_link = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, \"Fixtures\")))\n",
    "    fixtures_link.click()\n",
    "\n",
    "    # Wait for the fixtures page to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"js-list\")))\n",
    "\n",
    "    # Get the page source after the fixtures page has loaded\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find the elements containing fixture details\n",
    "    fixtures = soup.find_all(\"li\", class_=\"js-list\")\n",
    "\n",
    "    # Initialize lists to store the scraped data\n",
    "    series_list = []\n",
    "    place_list = []\n",
    "    date_list = []\n",
    "    time_list = []\n",
    "\n",
    "    # Iterate through the fixtures and extract the details\n",
    "    for fixture in fixtures:\n",
    "        series_list.append(fixture.find(\"p\", class_=\"fixture__additional-info\").text.strip())\n",
    "        place_list.append(fixture.find(\"p\", class_=\"fixture__additional-info\").find_next(\"span\").text.strip())\n",
    "        date_time = fixture.find(\"div\", class_=\"fixture__full-date\").text.strip()\n",
    "        date, time = date_time.split(\", \")\n",
    "        date_list.append(date)\n",
    "        time_list.append(time)\n",
    "\n",
    "    # Print or process the scraped data as needed\n",
    "    for i in range(len(series_list)):\n",
    "        print(f\"A) Series: {series_list[i]}\")\n",
    "        print(f\"B) Place: {place_list[i]}\")\n",
    "        print(f\"C) Date: {date_list[i]}\")\n",
    "        print(f\"D) Time: {time_list[i]}\")\n",
    "        print()\n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    print(f\"Element not found: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42494cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixtures link not found on the homepage.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL\n",
    "url = 'https://www.bcci.tv/'\n",
    "\n",
    "try:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check for any HTTP request errors\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the link to the international fixtures page\n",
    "    fixtures_link = soup.find('a', text='Fixtures')\n",
    "\n",
    "    if fixtures_link:\n",
    "        fixtures_url = 'https://www.bcci.tv' + fixtures_link['href']\n",
    "        response = requests.get(fixtures_url)\n",
    "\n",
    "        # Check for any HTTP request errors\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Create another BeautifulSoup object for the fixtures page\n",
    "        fixtures_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the elements containing fixture details\n",
    "        fixtures = fixtures_soup.find_all('li', class_='js-list')\n",
    "\n",
    "        # Initialize lists to store the scraped data\n",
    "        series_list = []\n",
    "        place_list = []\n",
    "        date_list = []\n",
    "        time_list = []\n",
    "\n",
    "        # Iterate through the fixtures and extract the details\n",
    "        for fixture in fixtures:\n",
    "            series = fixture.find('p', class_='fixture__additional-info').text.strip()\n",
    "            place = fixture.find('span', class_='fixture__additional-info').text.strip()\n",
    "            date = fixture.find('span', class_='fixture__date').text.strip()\n",
    "            time = fixture.find('span', class_='fixture__time').text.strip()\n",
    "\n",
    "            series_list.append(series)\n",
    "            place_list.append(place)\n",
    "            date_list.append(date)\n",
    "            time_list.append(time)\n",
    "\n",
    "        # Print or process the scraped data as needed\n",
    "        for i in range(len(series_list)):\n",
    "            print(f\"A) Series: {series_list[i]}\")\n",
    "            print(f\"B) Place: {place_list[i]}\")\n",
    "            print(f\"C) Date: {date_list[i]}\")\n",
    "            print(f\"D) Time: {time_list[i]}\")\n",
    "            print()\n",
    "\n",
    "    else:\n",
    "        print(\"Fixtures link not found on the homepage.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"HTTP request error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc74851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixtures link not found on the homepage.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL\n",
    "url = 'https://www.bcci.tv/'\n",
    "\n",
    "try:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check for any HTTP request errors\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the link to the international fixtures page\n",
    "    fixtures_link = soup.find('a', text='Fixtures')\n",
    "\n",
    "    if fixtures_link:\n",
    "        fixtures_url = 'https://www.bcci.tv' + fixtures_link['href']\n",
    "        response = requests.get(fixtures_url)\n",
    "        response.raise_for_status()  # Check for any HTTP request errors\n",
    "\n",
    "        # Create another BeautifulSoup object for the fixtures page\n",
    "        fixtures_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the elements containing fixture details\n",
    "        fixtures = fixtures_soup.find_all('li', class_='js-list')\n",
    "\n",
    "        # Initialize lists to store the scraped data\n",
    "        series_list = []\n",
    "        place_list = []\n",
    "        date_list = []\n",
    "        time_list = []\n",
    "\n",
    "        # Iterate through the fixtures and extract the details\n",
    "        for fixture in fixtures:\n",
    "            series = fixture.find('p', class_='fixture__additional-info').text.strip()\n",
    "            place = fixture.find('span', class_='fixture__additional-info').text.strip()\n",
    "            date = fixture.find('span', class_='fixture__date').text.strip()\n",
    "            time = fixture.find('span', class_='fixture__time').text.strip()\n",
    "\n",
    "            series_list.append(series)\n",
    "            place_list.append(place)\n",
    "            date_list.append(date)\n",
    "            time_list.append(time)\n",
    "\n",
    "        # Print or process the scraped data as needed\n",
    "        for i in range(len(series_list)):\n",
    "            print(f\"A) Series: {series_list[i]}\")\n",
    "            print(f\"B) Place: {place_list[i]}\")\n",
    "            print(f\"C) Date: {date_list[i]}\")\n",
    "            print(f\"D) Time: {time_list[i]}\")\n",
    "            print()\n",
    "\n",
    "    else:\n",
    "        print(\"Fixtures link not found on the homepage.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"HTTP request error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95096600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
